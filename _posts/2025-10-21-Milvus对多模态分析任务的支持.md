---
layout: post
title: " Milvus对多模态外任务的支持"
subtitle: "浮点数向量常用检索算法综述"
author: "Zihan Zhang"
header-style: text
tags:
  - 主线任务
  - Milvus
  - 向量检索算法


---

### 声明

由于本人能力问题，本文可能存在不严谨、不准确等问题。如有读者发现，欢迎发送邮件至zhangzihan.cs@gmail.com或在GitHub中对[本项目](https://github.com/zihan-zhang-cs/zihan-zhang-cs.github.io)发起issue。如果本篇文章帮助了你，欢迎点赞、收藏、star。

# Milvus对多模态外任务的支持

## 1. 总述

Milvus 是一个开源的云原生向量数据库，专为在海量向量数据集上进行高性能相似性搜索而设计。它建立在流行的向量搜索库（包括 Faiss、HNSW、DiskANN 和 SCANN）之上，可为人工智能应用和非结构化数据检索场景提供支持 [1]。

Milvus项目的GitHub地址为```https://github.com/milvus-io/milvus```，官方项目介绍地址为：```https://milvus.io/docs/zh/architecture_overview.md```。

![Architecture_diagram](https://milvus.io/docs/v2.6.x/assets/milvus_architecture_2_6.png)

由上图可知，Milvus由四层架构组成，分别是访问层、协调层、工作层与储存层。每层具体机制详见Milvus官方文档。

## 2. 向量的插入与删除

Milvus 采用流式数据摄入架构。流节点（DataNode）是负责从消息队列（如 Apache Pulsar）接收消息。流节点接收到的消息首先缓存在内存中，然后达到定量之后把它组织为一个segment自动flush到磁盘上面 [3]。

Milvus的一个数据库存储若干集合（Collection），类似于关系型数据库的表，是用于组织向量和标量数据的逻辑容器。集合支持以下功能：

- 向量存储：存储高维向量数据（如 FLOAT_VECTOR、BINARY_VECTOR、SPARSE_FLOAT_VECTOR），用于相似性搜索。
- 标量存储：存储元数据（如 INT64、VARCHAR、JSON），支持过滤和查询。
- 索引支持：为向量字段和标量字段创建索引，加速搜索和过滤。
- 一致性控制：支持多种一致性级别（如 strong、session），控制数据读取的新鲜度。
- 分片（Partition）：集合可分为多个分片，实现数据分片管理 [2]。

在 Milvus 中，你可以选择一个 Collections 使用多少个分片，每个分片映射到一个虚拟通道(vchannel）。Milvus 会将每个vchannel分配给一个物理通道（pchannel）（vchannel对pchannel是多对一的关系，即一个vchannel只能分配一个pchannel，但一个pchannel可能会接收若干vchannel的消息），每个pchannel绑定到一个特定的流节点。每个Vchannel内数据保持有序 [4]。这样做的好处是可以将逻辑与物理隔离开。后续添加更多的资源来扩展流节点时不需要更改虚拟通道，反之亦然。

综上所述，Milvus的数据写入流程为：

1. 一个Collection进行分片，每个分片为一个VChannel。
2. Proxy 会根据哈希策略（例如主键 hash）选择一个 VChannel写入数据。该 VChannel 实际上映射到底层的 PChannel。
3. 流节点检查PChaneel中数据达到一定的量，将其写入磁盘中。

![img](https://pic2.zhimg.com/v2-5de01218ee9166f4289adc592f82d7c3_1440w.jpg)

Milvus的向量存储形式为跨模态分析打下了基础。除此之外还有以下优势：

| 维度               | 机制                          | 带来的好处                       |
| ------------------ | ----------------------------- | -------------------------------- |
| **实时性**         | 流式数据摄入（DataNode + MQ） | 可实时处理多模态数据流           |
| **可扩展性**       | VChannel/PChannel 解耦        | 不同模态可独立扩展计算与存储     |
| **一致性与对齐性** | 每个 VChannel 内数据有序      | 保证时间和模态对应关系的精确对齐 |

## 3. 相似度算法的设计与实现

给定任意一向量求距离其最近的K个向量，针对不同的数据类型有不同算法：

|                         字段数据类型                         |                         适用索引类型                         |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
| FLOAT_VECTOR<br />FLOAT16_VECTOR<br />bfloat16_vector<br />INT8_VECTOR | FLAT<br />IVF_FLAT<br />IVF_SQ8<br />IVF_PQ<br />IVF_RABITQ<br />GPU_IVF_FLAT<br />GPU_IVF_PQ<br />HNSW<br />DISKANN |
|                          二进制向量                          |         BIN_FLAT<br />BIN_IVF_FLAT<br />MINHASH_LSH          |
|                         稀疏浮点矢量                         |                         稀疏反转索引                         |
|                           VARCHAR                            |              反转（推荐）<br />BITMAP<br />Trie              |
|                             BOOL                             |                   BITMAP（推荐）<br />反转                   |
|                     INT8INT16INT32INT64                      |                      反转<br />STL_SORT                      |
|                         FLOATDOUBLE                          |                             反转                             |
|      数组（BOOL、INT8/16/32/64 和 VARCHAR 类型的元素）       |                        BITMAP（推荐）                        |
| ARRAY（BOOL、INT8/16/32/64、FLOAT、DOUBLE 和 VARCHAR 类型的元素） |                             反转                             |
|                             JSON                             |                             反转                             |

其他类型的检索方法与浮点数向量类似，又因为实际工作中浮点数向量应用最为广泛，因此本文仅介绍浮点数向量的检索方法。

### 3.1 FLAT与IVF_FLAT

FLAT索引即暴力搜索，直接将每个查询向量与数据集中的每个向量进行比较，而无需任何高级预处理或数据结构。

IVF_FLAT（反转文件扁平）索引是一种可以提高浮点向量搜索性能的索引算法。首先对所有向量进行k-means 聚类，得到 $n_{list}$个聚类中心。查询时，首先用相同的聚类中心计算查询向量q到每个中心的距离。选取距离最近的nprobe个聚类中心（由用户设置，例如 10 或 20）。只在这些选定的分区中进行精确搜索（即直接用欧氏距离或内积计算相似度）。

其中，“反转”的含义如下：

![image-20251021090951523]((https://github.com/zihan-zhang-cs/zihan-zhang-cs.github.io/blob/master/_posts/assets/image-20251021090951523.png?raw=true))

后续IVF就是对数据先分区然后再在若干个分区内各自进行操作。

### 3.2 IVF_SQ8

标量量化（SQ）算法是将查找范围内每个向量同维度分量以下式进行归一化操作：
$$
normalized\_value= \frac{value−min}{max−min} 
$$
之后将各向量乘以255，再四舍五入取整，这样各分量的取值范围便局限在0-255，可以用一个8bit整数进行存储。提高了检索速度并使占用空间减少 4 倍。

### 3.3 IVF_PQ

（1） 向量划分

将高维向量$ x \in \mathbb{R}^D$ 划分为$m$个子向量：
$$
x = [x_1, x_2, \dots, x_m]
$$
其中每个子向量：
$$
x_i \in \mathbb{R}^{D/m}, \quad i = 1, 2, \dots, m
$$
（2）子量化器训练（K-means 聚类）

对每个子空间独立训练一个量化器：
$$
C_i = \{ c_{i1}, c_{i2}, \dots, c_{iK} \}, \quad i = 1, 2, \dots, m
$$
每个$ C_i $表示第$i$个子空间的聚类中心集合。

（3）编码（Quantization / Encoding）

将每个子向量映射到最近的聚类中心编号：
$$
\text{code}(x)_i = \arg\min_j \| x_i - c_{ij} \|, \quad j = 1, 2, \dots, K
$$
于是整个向量的编码为：
$$
\text{code}(x) = [\text{code}(x)_1, \text{code}(x)_2, \dots, \text{code}(x)_m]
$$




每个编码分量是一个整数（范围 $0 \sim K-1$）。

（4）距离查表（Lookup Table）

查询阶段，对查询向量 $q$ 也分块：
$$
q = [q_1, q_2, \dots, q_m]
$$
为每个子空间预计算距离查找表：
$$
D_i[j] = \| q_i - c_{ij} \|^2, \quad j = 1, 2, \dots, K
$$
（5）近似距离计算（Approximate Distance）

两个向量的近似欧式距离可通过查表法快速计算：
$$
\| q - x \|^2 \approx \sum_{i=1}^{m} D_i[\text{code}(x)_i]
$$

### 3.4 IVF_RaBitQ

原始算法较为复杂，我尝试理解后给出一个简化的理解方式：RaBitQ 就是把原始向量标准化后映射到超立方体的不同节点上，查询时找到最近的节点，再在这个节点的向量集中检索 top-k [5]。

其中的细节可以参考论文原始内容或ChatGPT给出的回答：

```markdown
## RaBitQ 算法介绍

![Image](https://media2.dev.to/dynamic/image/width%3D800%2Cheight%3D%2Cfit%3Dscale-down%2Cgravity%3Dauto%2Cformat%3Dauto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fa003ecvun8283fmpcsxt.png)

![Image](https://assets.zilliz.com/Figure_Compressing_a_vector_by_finding_its_closest_approximation_on_the_hypercube_so_that_each_dimension_can_be_represented_with_just_1_bit_cd0d50bb30.png)

![Image](https://cdn.sanity.io/images/me0ej585/search-labs-import-testing/5c1636541a2ae86307c00e726fe481320555641b-1440x1362.jpg)

下面我详细介绍 RaBitQ 算法，包括它的背景、关键思想、流程、优缺点以及应用场景。你也可以把它当作一个相对于 Product Quantization (PQ) 的“升级版”量化方法。

---

### 1. 背景与动机

* 在高维向量检索（近似最近邻，ANN）中，向量压缩（quantization）是节省存储、提升检索速度的关键技术。
  PQ、标量量化（SQ）等方法已被广泛使用。
* 但这些方法普遍存在一个问题：**缺少理论上的误差界（error bound）**，在一些真实数据集上可能出现效果不稳定。 ([arXiv][1])
* 为此，作者提出 RaBitQ —— 一种“**随机化量化（randomized quantization）**”方法，旨在提供 **可证明的误差界**，且在实践中表现优于 PQ 及其变种。 ([ACM Digital Library][2])
* 在具体系统如 Milvus 中，它被实现为索引类型之一（例如 IVF＋RaBitQ）以支持极高压缩率。 ([Milvus][3])

---

### 2. RaBitQ 的核心思想

RaBitQ 的几个关键词：**二值量化（或多位量化）**、**理论误差界**、**利用随机旋转／正交变换**。

* 它将 (D)-维浮点向量量化为 (D)-位（即每维 1 bit）或多 bit 的编码。论文最初主打 1 bit/维的版本。 ([arXiv][1])
* 量化过程中包含 **随机旋转 (random orthogonal transform)**，使得数据维度间的分布更均匀（减少偏置／冗余维度）――有助于量化效果。 ([cockroachlabs.com][4])
* 数据向量首先“中心化”到其所属簇（或聚类中心）后，再做单位化（unit‐normalize）或规范化处理。然后对每一维决定“正”或“负”、或者更细分的多位编码。 ([Elastic][5])
* 通过构建一个特殊的“码本 (codebook)”——例如高维超立方体 (hypercube) 的顶点——将每个向量映射至该码本中的一个点。 ([Corporate NTU][6])
* 在检索阶段，使用 **位操作（bitwise operations）** 或 **SIMD 加速 (SIMD‐based operations)** 来估算两个向量之间的距离／相似度，从而既快又省空间。 ([arXiv][1])
* 最重要的是：RaBitQ 给出了 **误差界**（error bound），也就是说它能保证量化后估算距离与真实距离之间的差别在可控范围之内。 ([arXiv][1])

---

### 3. 算法流程（高层次）

下面按“索引阶段（构建）”与“查询阶段”来分步说明 RaBitQ 的流程。

#### 3.1 索引（构建）阶段

1. **随机旋转／正交变换**：对所有原始数据向量 (x \in \mathbb R^D) 应用一个随机正交矩阵 (P)，获得 (x' = P x)（有些实现可能略简化）。 ([cockroachlabs.com][4])
2. **聚类／中心化**（如果结合 IVF 等机制）：将数据分簇，每个簇有中心 (c)；然后将向量减去其所在簇的中心，得到残差向量 (r = x' - c)。 ([arXiv][1])
3. **单位化／规范化**：将残差向量 (r) 规范至单位长度或在一定范围内，使各维具有类似规模。 例如 ( \tilde r = r / |r| )。
4. **码本构建**：构造一个高维超立方体码本 (每维 (\pm \frac{1}{\sqrt D}) 或类似形式) ——例如所有坐标为 ( \pm \frac{1}{\sqrt D} ) 的向量构成码本顶点。 ([Corporate NTU][6])
5. **量化映射**：对于每个向量 (\tilde r)，找到其“最近”码本向量（例如根据内积或欧氏距离）并用该码本向量的索引（或对应位编码）表示。若为 1 bit/维，则每维是 “正”或“负” (即 0 或 1)。
6. **预计算修正量**：为了在查询阶段估算距离更准确，RaBitQ 会存储一些修正量／辅助值，比如原向量与码本向量的点积、向量到中心的距离等。 ([Elastic][5])
7. **压缩存储**：最终存储的是每个向量的量化编码（bit 字符串） + 少量辅助标量值，而不必存储原浮点向量（或可选择保留以便在 reranking 时使用）。

#### 3.2 查询阶段

1. **查询预处理**：给定查询向量 (q)，同样应用旋转／中心化／单位化流程（与数据一致）。
2. **估算距离**：使用数据向量的 bit 编码以及预先存储的辅助数据，通过位操作或 SIMD 指令快速计算估算距离或相似度。

   * 例如，利用 (\tilde o)（量化后的码本向量）与 (q) 的交互来估算 ( \langle q, o \rangle ) 或 (|q-o|)。
   * 基于 RaBitQ 的公式（在 Milvus 文档中简化展示）可能类似：
     [
     \text{est_dist}(q, o) ;=; C(o_r, c_o) + \big\langle \tilde o,; q_r - c_o \big\rangle
     ]
     其中 (o_r) 是数据向量残差、(c_o) 是其簇中心、(\tilde o) 是量化后的 bit 向量。 ([Milvus][3])
3. **候选重排序 (optional)**：由于量化后为近似距离，常见做法是先快速选出 top-K 候选，再针对这些候选使用原始浮点向量或更精细的表示做“重排序 (reranking)”，以提高召回率。 ([Elastic][5])
4. **输出最终结果**。

---

### 4. 算法关键技术点

* **随机旋转**：减少维度之间的不均匀性，使量化误差更“平均”分布。
* **码本设计**：通过超立方体顶点设计，使量化向量简单且位编码可直接利用位运算。
* **位操作／SIMD 加速**：量化结果为 bit 或少量位宽编码，可以用硬件高效指令（例如 POPCNT、AVX512）快速处理。 ([Milvus][3])
* **理论误差界**：与 PQ 不同，RaBitQ 提供对估算距离／内积误差的数学界定，可用于提前预估检索质量。 ([OpenReview][7])
* **高压缩率**：典型为 1 bit/维，意味着如果原向量维度为 (D)，存储约为 (D) bits（理想情况下比原始 32-bit float 每维少了 32 倍）。例如，Milvus 文档中指出“1→32 压缩率”。 ([Milvus][3])

---

### 5. 优势与局限

#### 优势

* 极高的压缩率：可达 32× 或更高。
* 快速的距离估算：使用位操作／SIMD，速度高。
* 有理论保障的误差界：比一些经验方法（如 PQ）更稳健。
* 在实际系统（如 Milvus）中表现良好：既可保持较高召回率，又显著提升吞吐/降低内存。 ([Milvus][8])

#### 局限/注意事项

* 在极高压缩（如 1 bit/维）下，虽然表现不错，但仍有精度损失，需要可能的重排序 (reranking) 来弥补。
* 原始版本主要设计为 1 bit/维，虽然已有扩展（Extended RaBitQ 支持多位/维）但复杂度稍高。 ([DEV Community][9])
* 如果无重排序并且压缩率极高，可能召回率低于全精度或较低压缩方案。
* 对实现环境（如支持高级位操作、SIMD 指令集）有一定要求。

---

### 6. 应用场景

* 向量数据库系统中，对**大规模、高维度**数据进行检索，但希望**降低内存／存储成本**。
* 对**检索速度要求极高**且可以容忍一定近似误差的场景。
* 与分区索引（如 IVF）结合使用：例如 Milvus 的 `IVF_RABITQ` 索引类型。 ([Milvus][3])
* 在资源受限（内存/带宽受限）的部署环境中，压缩效率尤为重要。

---

### 7. 总结一句话

RaBitQ 是一种面向高维向量近似检索的量化算法，它通过随机旋转、二值（或少位）量化、高效位运算估算距离，并且提供理论误差界。它在压缩率、速度和检索性能之间实现了更优的平衡，是 PQ 等传统方法的重要升级。

---

如果你愿意，我还可以帮你查找 **RaBitQ 的数学公式**（包括编码映射、误差界推导、估算距离公式）并整理成可直接用于论文或报告的 LaTeX 版本。你要吗？

[1]: https://arxiv.org/abs/2405.12497?utm_source=chatgpt.com "RaBitQ: Quantizing High-Dimensional Vectors with a Theoretical Error Bound for Approximate Nearest Neighbor Search"
[2]: https://dl.acm.org/doi/pdf/10.1145/3654970?utm_source=chatgpt.com "RaBitQ: Quantizing High-Dimensional Vectors with a Theoretical ..."
[3]: https://milvus.io/docs/ivf-rabitq.md?utm_source=chatgpt.com "IVF_RABITQ | Milvus Documentation"
[4]: https://www.cockroachlabs.com/blog/cspann-real-time-indexing-billions-vectors/?utm_source=chatgpt.com "Real-Time Indexing for Billions of Vectors with CockroachDB"
[5]: https://www.elastic.co/search-labs/blog/rabitq-explainer-101?utm_source=chatgpt.com "RaBitQ binary quantization 101 - Elasticsearch Labs"
[6]: https://www.ntu.edu.sg/innovates/tech-portal/tech-offers/detail/rabitq-estimating-unit-vector-positioning-ml-systems?utm_source=chatgpt.com "RaBitQ: Estimating Unit Vector Positioning for ML Systems"
[7]: https://openreview.net/pdf?id=OeZHhOsFir&utm_source=chatgpt.com "[PDF] The RaBitQ Library - OpenReview"
[8]: https://milvus.io/blog/bring-vector-compression-to-the-extreme-how-milvus-serves-3%C3%97-more-queries-with-rabitq.md?utm_source=chatgpt.com "How Milvus Serves 3× More Queries with RaBitQ"
[9]: https://dev.to/gaoj0017/extended-rabitq-an-optimized-scalar-quantization-method-83m?utm_source=chatgpt.com "Extended RaBitQ: an Optimized Scalar Quantization Method"
```

### 3.5 HNSW算法

HNSW（Hierarchical Navigable Small World）几乎是当前向量数据库中使用最广泛、性能最优的近似最近邻（ANN）检索算法之一。其核心思想如下：

用户指定一个m，每个向量作为一个图中的节点与它最相邻的m个节点进行连接，这就构成了一个超空间中的图。每个向量遵循一个概率分布生成一个最高层级，这个概率分布一般是随层级越高而指数递减的。每一层包含了最高层级大于等于这一层数的节点。第零层包含了所有节点。这样任意节点N在进行检索时，只需要在最高层检索最近节点$N_{i}$，之后进入下一层，在$N_{i}$的相邻节点中检索与N最相近的节点$N_{i-1}$。以此类推，直至检索到第0层。

HNSW不能保证找到全局最优的最近邻（即精确最近邻），它找到的是一个近似最近邻（Approximate Nearest Neighbor, ANN）。

![HNSW](https://milvus.io/docs/v2.6.x/assets/hnsw.png)



## 4. 总结

本文简要分析了Milvus数据库所支持的向量检索办法。向量型数据库以向量形式存储不同模态数据下的共有特征，这为跨模态分析提供了支撑。了解向量检索方法的原理可以更好地优化跨模态分析算法以及工程上的Debug。

___

参考资料

[1] Milvus. (n.d.). *Milvus 架构概述*. Milvus 官方文档. https://milvus.io/docs/zh/architecture_overview.md

[2] u013172930. (2025, April 28). 【Milvus】集合 (Collections) 的概述和操作. CSDN 博客. https://blog.csdn.net/u013172930/article/details/147566281

[3] Zilliz. (2022, July 01). Milvus 2.0 数据插入与持久化. 知乎专栏. https://zhuanlan.zhihu.com/p/486971488

[4] Milvus. (n.d.). 数据处理. Milvus 官方文档. https://milvus.io/docs/zh/data_processing.md

[5] Gao, J., & Long, C. (2024). RaBitQ: Quantizing high-dimensional vectors with a theoretical error bound for approximate nearest neighbor search. *Proceedings of the 2024 International Conference on Management of Data (SIGMOD '24)* (pp. 1-22). Association for Computing Machinery. [Preprint](https://arxiv.org/abs/2405.12497)
